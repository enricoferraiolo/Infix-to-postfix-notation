{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPFPtHankgU8"
      },
      "source": [
        "# Project Description:\n",
        "\n",
        "The purpose of this project is to implement a neural network that performs the translation of mathematical formulae from traditional **infix notation**—where the operator appears between two operands—to **postfix** (also known as Reverse Polish Notation), where the operator follows the operands.\n",
        "\n",
        "Infix notation is the most commonly used in human-readable mathematics (e.g., a + b), but it is inherently ambiguous without additional syntactic aids such as parentheses or operator precedence rules. This ambiguity arises because different parse trees can correspond to the same expression depending on how operations are grouped.\n",
        "\n",
        "In contrast, postfix notation eliminates the need for parentheses entirely. The order of operations is explicitly encoded by the position of the operators relative to the operands, making it more suitable for stack-based evaluation and easier to parse programmatically.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Consider the ambiguous infix expression:\n",
        "a + b * c\n",
        "\n",
        "This expression can be parsed in at least two different ways:\n",
        "\n",
        "Interpretation (Infix):\t(a + b) * c\t   \n",
        "Equivalent Postfix: ab+c*\n",
        "\n",
        "Interpretation (Infix):\ta + (b * c)\t          \n",
        "Equivalent Postfix: abc*+\n",
        "\n",
        "\n",
        "This project aims to learn such disambiguations and generate the correct postfix form from a given infix expression using a data-driven approach based on neural networks. To simplify the task and control the complexity of expressions, we restrict our dataset to formulae with a maximum syntactic depth of 3. This means that the abstract syntax trees representing these expressions will have at most three levels, ensuring that the neural network operates on a bounded and manageable set of possible structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i_tRkF6n6smU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-11 12:10:44.094238: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-06-11 12:10:44.099522: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-06-11 12:10:44.115403: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749636644.143271    7303 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749636644.150632    7303 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749636644.170206    7303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749636644.170234    7303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749636644.170238    7303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749636644.170242    7303 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-11 12:10:44.176620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFSHpEHjpa1x"
      },
      "source": [
        "We build formulae using 5 identifiers a,b,c,d,e and 4 binary operators +,-,*,/.\n",
        "For simplicity we do not take advantage of precedence or associativity rules for infix notation, and suppose that all binary operations as always fully parenthesizes: (e1 op e2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IINM81OK61pH"
      },
      "outputs": [],
      "source": [
        "# -------------------- Constants --------------------\n",
        "OPERATORS = ['+', '-', '*', '/']\n",
        "IDENTIFIERS = list('abcde')\n",
        "SPECIAL_TOKENS = ['PAD', 'SOS', 'EOS']\n",
        "SYMBOLS = ['(', ')', '+', '-', '*', '/']\n",
        "VOCAB = SPECIAL_TOKENS + SYMBOLS + IDENTIFIERS + ['JUNK'] #may use junk in autoregressive generation\n",
        "\n",
        "token_to_id = {tok: i for i, tok in enumerate(VOCAB)}\n",
        "id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "PAD_ID = token_to_id['PAD']\n",
        "EOS_ID = token_to_id['EOS']\n",
        "SOS_ID = token_to_id['SOS']\n",
        "\n",
        "MAX_DEPTH = 3\n",
        "MAX_LEN = 4*2**MAX_DEPTH -2 #enough to fit expressions at given depth (+ EOS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T-fO911d6_FW"
      },
      "outputs": [],
      "source": [
        "# -------------------- Expression Generation --------------------\n",
        "def generate_infix_expression(max_depth):\n",
        "    if max_depth == 0:\n",
        "        return random.choice(IDENTIFIERS)\n",
        "    elif random.random() < 0.5:\n",
        "        return generate_infix_expression(max_depth - 1)\n",
        "    else:\n",
        "        left = generate_infix_expression(max_depth - 1)\n",
        "        right = generate_infix_expression(max_depth - 1)\n",
        "        op = random.choice(OPERATORS)\n",
        "        return f'({left} {op} {right})'\n",
        "\n",
        "def tokenize(expr):\n",
        "    return [c for c in expr if c in token_to_id]\n",
        "\n",
        "def infix_to_postfix(tokens):\n",
        "    precedence = {'+': 1, '-': 1, '*': 2, '/': 2}\n",
        "    output, stack = [], []\n",
        "    for token in tokens:\n",
        "        if token in IDENTIFIERS:\n",
        "            output.append(token)\n",
        "        elif token in OPERATORS:\n",
        "            while stack and stack[-1] in OPERATORS and precedence[stack[-1]] >= precedence[token]:\n",
        "                output.append(stack.pop())\n",
        "            stack.append(token)\n",
        "        elif token == '(':\n",
        "            stack.append(token)\n",
        "        elif token == ')':\n",
        "            while stack and stack[-1] != '(':\n",
        "                output.append(stack.pop())\n",
        "            stack.pop()\n",
        "    while stack:\n",
        "        output.append(stack.pop())\n",
        "    return output\n",
        "\n",
        "def encode(tokens, max_len=MAX_LEN):\n",
        "    ids = [token_to_id[t] for t in tokens] + [EOS_ID]\n",
        "    return ids + [PAD_ID] * (max_len - len(ids))\n",
        "\n",
        "def decode_sequence(token_ids, id_to_token, pad_token='PAD', eos_token='EOS'):\n",
        "    \"\"\"\n",
        "    Converts a list of token IDs into a readable string by decoding tokens.\n",
        "    Stops at the first EOS token if present, and ignores PAD tokens.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    for token_id in token_ids:\n",
        "        token = id_to_token.get(token_id, '?')\n",
        "        if token == eos_token:\n",
        "            break\n",
        "        if token != pad_token:\n",
        "            tokens.append(token)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def generate_dataset(n,max_depth=MAX_DEPTH):\n",
        "    X, Y = [], []\n",
        "    for _ in range(n):\n",
        "        expr = generate_infix_expression(MAX_DEPTH)\n",
        "        #expr = expr_gen.generate(max_depth=max_dthep)\n",
        "        infix = tokenize(expr)\n",
        "        postfix = infix_to_postfix(infix)\n",
        "        X.append(encode(infix))\n",
        "        Y.append(encode(postfix))\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "#you might use the shift function for teacher-forcing\n",
        "def shift_right(seqs):\n",
        "    shifted = np.zeros_like(seqs)\n",
        "    shifted[:, 1:] = seqs[:, :-1]\n",
        "    shifted[:, 0] = SOS_ID\n",
        "    return shifted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DENVmP3Jq5Zf"
      },
      "source": [
        "Let us define a simple dataset, and inspect a few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gdlonKn47dE7"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = generate_dataset(10000)\n",
        "decoder_input_train = shift_right(Y_train)\n",
        "\n",
        "# Dataset\n",
        "X_val, Y_val = generate_dataset(1000)\n",
        "decoder_input_val = shift_right(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TogClrT6F2Th",
        "outputId": "7ef901de-8fe1-4724-870e-d755135aeb0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1765\n",
            "infix :  ( e - ( e * e ) )\n",
            "posfix notation:  e e e * -\n",
            "teacher forcing :  SOS e e e * -\n"
          ]
        }
      ],
      "source": [
        "i =  np.random.randint(10000)\n",
        "print(i)\n",
        "print(\"infix : \",decode_sequence(X_train[i],id_to_token))\n",
        "print(\"posfix notation: \",decode_sequence(Y_train[i],id_to_token))\n",
        "print(\"teacher forcing : \", decode_sequence(decoder_input_train[i],id_to_token))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgqDkVaztBuv"
      },
      "source": [
        "# Constraints\n",
        "* You may use any architecture (decoder-only, encoder-decoder, or other).\n",
        "\n",
        "* The maximum number of parameters is 2 million.\n",
        "\n",
        "* Beam search is not allowed.\n",
        "\n",
        "* You may adapt the formula generator to your needs, but preserve its core logic—especially the frequency distribution of formulas by depth, as it may significantly influence model performance.\n",
        "\n",
        "* You may train your model using a pre-generated fixed dataset (e.g., an array) or directly use an on-the-fly generator.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDUjK4SGvT0s"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We shall evaluate a generated item y_pred using \"prefix accuracy\", the lenght of\n",
        "the initial prefix of y_pred matching the ground true y_true. This will be divided by the maximum length of y_true and y_pred (up to EOS), so that a perfect match has score 1.\n",
        "\n",
        "* It's more informative than exact match (which is often 0)\n",
        "\n",
        "* It’s tighter than edit distance: focuses on generation flow\n",
        "\n",
        "* Captures where the model starts to make errors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MeqyasiYxCpU"
      },
      "outputs": [],
      "source": [
        "def prefix_accuracy_single(y_true, y_pred, id_to_token, eos_id=EOS_ID, verbose=False):\n",
        "    t_str = decode_sequence(y_true, id_to_token).split(' EOS')[0]\n",
        "    p_str = decode_sequence(y_pred, id_to_token).split(' EOS')[0]\n",
        "    t_tokens = t_str.strip().split()\n",
        "    p_tokens = p_str.strip().split()\n",
        "    max_len = max(len(t_tokens), len(p_tokens))\n",
        "\n",
        "    match_len = sum(x == y for x, y in zip(t_tokens, p_tokens))\n",
        "    score = match_len / max_len if max_len>0 else 0\n",
        "\n",
        "    if verbose:\n",
        "        print(\"TARGET :\", ' '.join(t_tokens))\n",
        "        print(\"PREDICT:\", ' '.join(p_tokens))\n",
        "        print(f\"PREFIX MATCH: {match_len}/{len(t_tokens)} → {score:.2f}\")\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeCRiqvsxQax"
      },
      "source": [
        "For the exam, evaluate you model on a test set of 20 expressions. Repeat this evaluation 10 times, and return the mean and std for this rounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-11 12:10:46.545675: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "\n",
        "# 1. Positional Encoding\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
        "    )\n",
        "    # apply sin to even indices in the array; cos to odd indices\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]  # shape (1, position, d_model)\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# 2. Masking\n",
        "def create_padding_mask(seq):\n",
        "    # seq: (batch_size, seq_len), padded with PAD_ID\n",
        "    mask = tf.cast(tf.math.equal(seq, PAD_ID), tf.float32)\n",
        "    # add extra dimensions to add the padding to the attention logits.\n",
        "    # shape: (batch_size, 1, 1, seq_len)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    # mask the future tokens: shape (size, size)\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    # 1s in upper triangle (excluding diagonal), 0s elsewhere\n",
        "    return mask  # will broadcast as needed\n",
        "\n",
        "\n",
        "# 3. Transformer encoder & decoder layers\n",
        "class EncoderLayer(layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(dff, activation=\"relu\"), layers.Dense(d_model)]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "        # x: (batch_size, seq_len, d_model)\n",
        "        attn_output = self.mha(\n",
        "            query=x, value=x, key=x, attention_mask=mask\n",
        "        )  # (batch_size, seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        return out2\n",
        "\n",
        "\n",
        "class DecoderLayer(layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.mha2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(dff, activation=\"relu\"), layers.Dense(d_model)]\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "        self.dropout3 = layers.Dropout(rate)\n",
        "\n",
        "    def call(\n",
        "        self, x, enc_output, training=None, look_ahead_mask=None, padding_mask=None\n",
        "    ):\n",
        "        # x: (batch_size, target_seq_len, d_model)\n",
        "        # enc_output: (batch_size, inp_seq_len, d_model)\n",
        "        # look_ahead_mask: for masking future tokens in decoder self-attention\n",
        "        # padding_mask: to mask encoder output padding in cross-attention\n",
        "        attn1 = self.mha1(\n",
        "            query=x, value=x, key=x, attention_mask=look_ahead_mask\n",
        "        )  # self-attn\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2 = self.mha2(\n",
        "            query=out1, value=enc_output, key=enc_output, attention_mask=padding_mask\n",
        "        )  # cross-attn\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(\n",
        "            ffn_output + out2\n",
        "        )  # (batch_size, target_seq_len, d_model)\n",
        "        return out3\n",
        "\n",
        "\n",
        "class Encoder(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        input_vocab_size,\n",
        "        maximum_position_encoding,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
        "        ]\n",
        "        self.dropout = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        # embedding + positional encoding\n",
        "        x = self.embedding(x)  # (batch_size, seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
        "        return x  # (batch_size, seq_len, d_model)\n",
        "\n",
        "\n",
        "class Decoder(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        num_heads,\n",
        "        dff,\n",
        "        target_vocab_size,\n",
        "        maximum_position_encoding,\n",
        "        rate=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [\n",
        "            DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
        "        ]\n",
        "        self.dropout = layers.Dropout(rate)\n",
        "\n",
        "    def call(\n",
        "        self, x, enc_output, training=None, look_ahead_mask=None, padding_mask=None\n",
        "    ):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.dec_layers[i](\n",
        "                x,\n",
        "                enc_output,\n",
        "                training=training,\n",
        "                look_ahead_mask=look_ahead_mask,\n",
        "                padding_mask=padding_mask,\n",
        "            )\n",
        "        # x: (batch_size, target_seq_len, d_model)\n",
        "        return x\n",
        "\n",
        "\n",
        "# 4. Full Transformer\n",
        "def build_transformer(\n",
        "    input_vocab_size,\n",
        "    target_vocab_size,\n",
        "    num_layers=2,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dff=512,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=0.1,\n",
        "):\n",
        "    # Inputs\n",
        "    encoder_inputs = layers.Input(\n",
        "        shape=(None,), name=\"encoder_inputs\"\n",
        "    )  # (batch_size, inp_seq_len)\n",
        "    decoder_inputs = layers.Input(\n",
        "        shape=(None,), name=\"decoder_inputs\"\n",
        "    )  # (batch_size, tar_seq_len)\n",
        "\n",
        "    # Masks\n",
        "    enc_padding_mask = layers.Lambda(create_padding_mask, name=\"enc_padding_mask\")(\n",
        "        encoder_inputs\n",
        "    )\n",
        "    dec_padding_mask = layers.Lambda(create_padding_mask, name=\"dec_padding_mask\")(\n",
        "        encoder_inputs\n",
        "    )\n",
        "\n",
        "    # look-ahead mask for decoder self-attention\n",
        "    # We'll build look-ahead mask dynamically inside a Lambda:\n",
        "    def compute_look_ahead_mask(x):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        mask = create_look_ahead_mask(seq_len)\n",
        "        return mask  # shape (seq_len, seq_len)\n",
        "\n",
        "    look_ahead_mask = layers.Lambda(compute_look_ahead_mask, name=\"look_ahead_mask\")(\n",
        "        decoder_inputs\n",
        "    )\n",
        "    # also need decoder padding mask for encoder-decoder attention: same as dec_padding_mask above\n",
        "\n",
        "    # Encoder\n",
        "    encoder = Encoder(\n",
        "        num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate\n",
        "    )\n",
        "    enc_output = encoder(\n",
        "        encoder_inputs, mask=enc_padding_mask\n",
        "    )  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # Decoder\n",
        "    decoder = Decoder(\n",
        "        num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate\n",
        "    )\n",
        "    dec_output = decoder(\n",
        "        decoder_inputs,\n",
        "        enc_output,\n",
        "        look_ahead_mask=look_ahead_mask,\n",
        "        padding_mask=dec_padding_mask,\n",
        "    )  # (batch_size, tar_seq_len, d_model)\n",
        "\n",
        "    # Final linear layer\n",
        "    final_output = layers.Dense(target_vocab_size, name=\"final_dense\")(\n",
        "        dec_output\n",
        "    )  # (batch_size, tar_seq_len, vocab_size)\n",
        "\n",
        "    return Model(inputs=[encoder_inputs, decoder_inputs], outputs=final_output)\n",
        "\n",
        "\n",
        "# 5. Loss & Metrics\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    # real: (batch_size, seq_len), pred: (batch_size, seq_len, vocab_size)\n",
        "    mask = tf.cast(tf.not_equal(real, PAD_ID), tf.float32)\n",
        "    loss_ = loss_object(real, pred)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    # real: (batch_size, seq_len), pred: (batch_size, seq_len, vocab_size)\n",
        "    pred_ids = tf.argmax(pred, axis=-1, output_type=tf.int32)\n",
        "    matches = tf.cast(tf.equal(real, pred_ids), tf.float32)\n",
        "    mask = tf.cast(tf.not_equal(real, PAD_ID), tf.float32)\n",
        "    matches *= mask\n",
        "    return tf.reduce_sum(matches) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "# 6. Hyperparameters (tune as needed)\n",
        "num_layers = 2\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "dff = 512\n",
        "# Estimate max sequence lengths for positional encodings: e.g. based on max infix/postfix lengths\n",
        "# Suppose you padded/generate sequences up to max_len (you know from your encode logic).\n",
        "# For safety, set pe_input and pe_target to something >= max length, e.g. 100.\n",
        "pe_input = 100\n",
        "pe_target = 100\n",
        "\n",
        "# Build model\n",
        "transformer = build_transformer(\n",
        "    input_vocab_size=VOCAB_SIZE,\n",
        "    target_vocab_size=VOCAB_SIZE,\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    pe_input=pe_input,\n",
        "    pe_target=pe_target,\n",
        "    rate=0.1,\n",
        ")\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=loss_function,\n",
        "    metrics=[accuracy_function],\n",
        ")\n",
        "\n",
        "\n",
        "# 7. Prepare data for training\n",
        "# Example: generate a dataset, pad to fixed length\n",
        "def prepare_data(batch_size=64, num_samples=10000, max_len=50):\n",
        "    # generate_dataset returns numpy arrays of shape (n, seq_len) with integer IDs, likely padded/truncated.\n",
        "    X, Y = generate_dataset(num_samples)\n",
        "    # Determine max lengths (or specify beforehand)\n",
        "    # Here assume X and Y are already padded to same length; otherwise we need to pad them:\n",
        "    # e.g. pad sequences to max_len with PAD_ID on right.\n",
        "    # For simplicity, assume generate_dataset gives fixed-length arrays; if not, do:\n",
        "    X = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        X, maxlen=max_len, padding=\"post\", value=PAD_ID\n",
        "    )\n",
        "    Y = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        Y, maxlen=max_len, padding=\"post\", value=PAD_ID\n",
        "    )\n",
        "    # Decoder inputs: shift_right(Y)\n",
        "    dec_inputs = shift_right(Y)\n",
        "    return X, dec_inputs, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  9/282\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 730ms/step - accuracy_function: 0.1096 - loss: 3.0277"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m epochs = \u001b[32m1\u001b[39m\n\u001b[32m      4\u001b[39m X_train, dec_inp_train, Y_train = prepare_data(\n\u001b[32m      5\u001b[39m     batch_size=\u001b[32m64\u001b[39m, num_samples=\u001b[32m20000\u001b[39m, max_len=\u001b[32m50\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_inp_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Infix-to-postfix-notation/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "X_train, dec_inp_train, Y_train = prepare_data(\n",
        "    batch_size=64, num_samples=20000, max_len=50\n",
        ")\n",
        "transformer.fit(\n",
        "    [X_train, dec_inp_train],\n",
        "    Y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR-9eTs28x4l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round= 0\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'autoregressive_decode' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     rscores.append(np.mean(scores))\n\u001b[32m     12\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(rscores),np.std(rscores)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m res, std = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mscore=\u001b[39m\u001b[33m\"\u001b[39m,res,\u001b[33m\"\u001b[39m\u001b[33mstd=\u001b[39m\u001b[33m\"\u001b[39m,std)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(no, rounds)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no):\n\u001b[32m      8\u001b[39m   encoder_input=X_test[j]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m   generated = \u001b[43mautoregressive_decode\u001b[49m(model, encoder_input)[\u001b[32m1\u001b[39m:] \u001b[38;5;66;03m#remove SOS\u001b[39;00m\n\u001b[32m     10\u001b[39m   scores.append(prefix_accuracy_single(Y_test[j], generated, id_to_token))\n\u001b[32m     11\u001b[39m rscores.append(np.mean(scores))\n",
            "\u001b[31mNameError\u001b[39m: name 'autoregressive_decode' is not defined"
          ]
        }
      ],
      "source": [
        "def test(no=20,rounds=10):\n",
        "  rscores =[]\n",
        "  for i in range(rounds):\n",
        "    print(\"round=\",i)\n",
        "    X_test, Y_test = generate_dataset(no)\n",
        "    scores = []\n",
        "    for j in range(no):\n",
        "      encoder_input=X_test[j]\n",
        "      generated = autoregressive_decode(model, encoder_input)[1:] #remove SOS\n",
        "      scores.append(prefix_accuracy_single(Y_test[j], generated, id_to_token))\n",
        "    rscores.append(np.mean(scores))\n",
        "  return np.mean(rscores),np.std(rscores)\n",
        "\n",
        "res, std = test(20,10)\n",
        "print(\"score=\",res,\"std=\",std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxxXPqKQ86fZ"
      },
      "source": [
        "Be sure to evalutate the generator: your model may only take as input the expression in infix format and return its translation to postifix.\n",
        "\n",
        "If you are usuing an encoder-decoder model, generation must be done autoregressively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOBottQI9o1h"
      },
      "source": [
        "# What to deliver\n",
        "\n",
        "As usual you are supposed to deliver a single notebook witten in Keras. You are auhtorized to use Keras3 with pytorch as backend if your prefer.\n",
        "\n",
        "Do no upload a zip file: the submission will be rejected.\n",
        "\n",
        "The python notebook should have a clear documentation of the training phase, possibly with its history.\n",
        "\n",
        "You should be able to provide the network paramters upon request. Even better, consider a way to upload them inside your notebook using gdown."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
